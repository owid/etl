# Learn more at:
# http://docs.owid.io/projects/etl/architecture/metadata/reference/
meta:
  origin:
    # Data product / Snapshot
    title: Tracking Compute-Intensive AI Models
    description: |-
      A dataset that tracks compute-intensive AI models, with training compute over 10²³ floating point operations (FLOP). This corresponds to training costs of hundreds of thousands of dollars or more. 

      To identify compute-intensive AI models, the team at Epoch AI used various resources, estimating compute when not directly reported. They included benchmarks and repositories, such as Papers With Code and Hugging Face, to find models exceeding 10²³ FLOP. They also explored non-English media and specific leaderboards, particularly focusing on Chinese sources.

      Additionally, they examined blog posts, press releases from major labs, and scholarly literature to track new models. A separate table was created for models with unconfirmed but plausible compute levels. Despite thorough methods, proprietary and secretive models may have been missed.
    date_published: "2024-06-19"

    # Citation
    producer: Epoch
    citation_full: |-
      Robi Rahman, David Owen and Josh You (2024), "Tracking Compute-Intensive AI Models". Published online at epochai.org. Retrieved from: 'https://epochai.org/blog/tracking-compute-intensive-ai-models' [online resource]

    # Files
    url_main: https://epochai.org/blog/tracking-compute-intensive-ai-models
    url_download: https://epochai.org/data/epochdb/large_scale_ai_models.csv
    date_accessed: 2024-08-05

    # License
    license:
      name: CC BY 4.0
      url: https://epochai.org/blog/how-much-does-it-cost-to-train-frontier-ai-models
outs:
  - md5: 8e02d8b9837c38766e230fc91dfd41ab
    size: 410761
    path: epoch_compute_intensive.csv
