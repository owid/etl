{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHO Global Health Observatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dest_dir = \"/tmp/gho_20210701\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from os import path, listdir\n",
    "import shutil\n",
    "import zipfile\n",
    "from typing import List\n",
    "import glob\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from owid import walden, catalog\n",
    "from etl.steps.data import converters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetch from walden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = walden.Catalog().find_one(\"who\", \"2021-07-01\", \"gho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = tempfile.mkdtemp(prefix=\"etl-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile.ZipFile(raw_dataset.local_path).extractall(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = path.join(tmp_dir, \"who_gho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = {\n",
    "    path.basename(f)[:-4]: f for f in sorted(glob.glob(path.join(src_dir, \"*.csv\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(csv_files.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a dataset container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = catalog.Dataset.create_empty(dest_dir)\n",
    "ds.metadata = converters.convert_walden_metadata(raw_dataset)\n",
    "ds.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the set of indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pd.read_csv(csv_files[\"_indicators\"])\n",
    "ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ind[\"Language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.columns = [\"orig_code\", \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owid.catalog import utils\n",
    "\n",
    "ind[\"code\"] = ind.orig_code.apply(utils.underscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.set_index(\"code\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = catalog.Table(ind)\n",
    "t.metadata.short_name = \"indicators\"\n",
    "t.metadata.title = \"List of all indicators provided in the GHE dataset\"\n",
    "ds.add(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Add each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_table(df: pd.DataFrame) -> List[catalog.Table]:\n",
    "    \"\"\"\n",
    "    We have have multiple different primary keys here.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    del df[\"Id\"]\n",
    "\n",
    "    assert len(df[\"IndicatorCode\"].unique()) == 1\n",
    "    indicator = utils.underscore(df[\"IndicatorCode\"].iloc[0])\n",
    "    del df[\"IndicatorCode\"]\n",
    "\n",
    "    # prefix the geo code for everything except countries, to avoid confusion\n",
    "    df[\"geo\"] = [\n",
    "        get_geo(_type, code)\n",
    "        for _type, code in zip(df.pop(\"SpatialDimType\"), df.pop(\"SpatialDim\"))\n",
    "    ]\n",
    "\n",
    "    tables = []\n",
    "    for keys, st in df.groupby(\n",
    "        [\"TimeDimType\", \"Dim1Type\", \"Dim2Type\", \"Dim3Type\", \"DataSourceDimType\"],\n",
    "        dropna=False,\n",
    "        as_index=False,\n",
    "    ):\n",
    "        st = st.copy()\n",
    "\n",
    "        dims = [\"geo\"]\n",
    "        for dim in [\"TimeDim\", \"Dim1\", \"Dim2\", \"Dim3\", \"DataSourceDim\"]:\n",
    "            dim_type = dim + \"Type\"\n",
    "\n",
    "            # not all dimensions are used\n",
    "            if pd.isnull(st[dim]).all():\n",
    "                del st[dim]\n",
    "                del st[dim_type]\n",
    "                continue\n",
    "\n",
    "            assert len(st[dim_type].unique()) == 1\n",
    "\n",
    "            col = st[dim_type].dropna().iloc[0].lower()\n",
    "            del st[dim_type]\n",
    "            st.rename({dim: col}, axis=1, inplace=True)\n",
    "\n",
    "            dims.append(col)\n",
    "\n",
    "        st.set_index(dims, inplace=True)\n",
    "\n",
    "        # if any rows are all empty, just prune them\n",
    "        st.dropna(how=\"all\")\n",
    "\n",
    "        # fix the value column\n",
    "        if not st.NumericValue.isnull().all():\n",
    "            st.rename({\"NumericValue\": indicator}, axis=1, inplace=True)\n",
    "            del st[\"Value\"]\n",
    "        else:\n",
    "            st.rename({\"Value\": indicator}, axis=1, inplace=True)\n",
    "            del st[\"NumericValue\"]\n",
    "\n",
    "        del st[\"TimeDimensionValue\"]\n",
    "        del st[\"TimeDimensionBegin\"]\n",
    "        del st[\"TimeDimensionEnd\"]\n",
    "\n",
    "        for col in [\"Low\", \"High\", \"Comments\"]:\n",
    "            if not st[col].isnull().all():\n",
    "                st.rename({col: f\"{indicator}_{col.lower()}\"}, axis=1, inplace=True)\n",
    "            else:\n",
    "                del st[col]\n",
    "\n",
    "        del st[\"Date\"]\n",
    "\n",
    "        t = catalog.Table(st)\n",
    "        t.metadata.short_name = indicator\n",
    "        tables.append(t)\n",
    "\n",
    "    if len(tables) > 1:\n",
    "        # rename each one to make it unique\n",
    "        for t in tables:\n",
    "            _hash = hashlib.md5(\",\".join(t.primary_key).encode(\"utf8\")).hexdigest()\n",
    "            t.metadata.short_name += \"_\" + _hash[:4]\n",
    "\n",
    "    for t in tables:\n",
    "        t.metadata.title = ind.loc[indicator, \"title\"]\n",
    "\n",
    "    return tables\n",
    "\n",
    "\n",
    "def get_geo(_type, code):\n",
    "    if pd.isnull(code):\n",
    "        return None\n",
    "    if _type == \"COUNTRY\":\n",
    "        return code\n",
    "    return f\"{_type.lower()}:{code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_VALUES = [\n",
    "    \"\",\n",
    "    \"Data not available\",\n",
    "    \"Not applicable\",\n",
    "    \"Not available\",\n",
    "    \"Not available.\",\n",
    "]\n",
    "\n",
    "for indicator, filename in sorted(csv_files.items()):\n",
    "    if indicator.startswith(\"_\"):\n",
    "        # skip metadata\n",
    "        continue\n",
    "\n",
    "    print(indicator)\n",
    "    df = pd.read_csv(filename, na_values=NA_VALUES)\n",
    "    for t in transform_table(df):\n",
    "        print(\"  \", t.metadata.short_name, t.primary_key, \"-->\", [c for c in t.columns])\n",
    "        ds.add(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7e386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6acb1f56450d2fb4e25ced3e1667354a814284a0c24faff8ce804d657da1734"
  },
  "kernelspec": {
   "display_name": "etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
