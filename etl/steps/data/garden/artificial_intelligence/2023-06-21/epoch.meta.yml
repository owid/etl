dataset:
  title: Parameter, Compute and Data Trends in Machine Learning (Epoch, 2023)
  description: >-
    We update this chart with the latest available data from our source every month.


    The authors selected the AI systems for inclusion based on the following necessary criteria:
    — Have an explicit learning component

    — Showcase experimental results

    — Advance the state of the art


    In addition, the systems had to meet at least one of the following notability criteria:
    — Paper has more than 1000 citations

    — Historical importance

    — Important state-of-the-art advance

    — Deployed in a notable context


    The authors note that: "For new models (from 2020 onward) it is harder to assess these criteria, so we fall back to a subjective selection. We refer to models meeting our selection criteria as 'milestone models.'"
  licenses:
  - name: Public domain
  sources:
  - name: Epoch (2023)
    url: https://epochai.org/mlinputs/visualization
    date_accessed: '2023-06-21'
    publication_date: '2023-06-06'
    publication_year: 2023
    published_by: 'Epoch, Parameter, Compute and Data Trends in Machine Learning.
      Published online at epochai.org. Retrieved from: https://epochai.org/mlinputs/visualization'
tables:
  epoch:
    variables:
      system:
        title: Name of the model
        unit: ''
      domain:
        title: Domain
        unit: ''
      publication_date:
        title: Publication date
        unit: 'date'
      organization_categorization:
        title: Researcher affiliation
        unit: ''
      parameters:
        title: Number of parameters
        description: >-
          The number of parameters in AI models refers to the total count of learnable variables or weights that the model contains. Parameters are the internal variables that the model adjusts during the training process to optimize its performance and make predictions based on the input data.


          In the context of deep learning models, which are a type of AI model, parameters are typically associated with the connections between the neurons or units in the neural network. Each connection has a weight associated with it, and these weights collectively represent the parameters of the model.


          The number of parameters in a model depends on its architecture and complexity. Deep learning models often have multiple layers, each containing numerous neurons or units. The connections between these units contribute to the overall parameter count. Additionally, other components such as convolutional filters, recurrent connections, and attention mechanisms also add to the parameter count.


          The number of parameters in AI models has a significant impact on model capacity and its ability to learn complex patterns from data. A larger number of parameters can allow the model to capture more intricate relationships and potentially achieve higher accuracy. However, it also increases the risk of overfitting, where the model becomes too specialized to the training data and performs poorly on unseen examples. Balancing the number of parameters to avoid overfitting while maintaining sufficient model capacity is a crucial consideration in model design.


          In recent years, AI models with billions or even trillions of parameters have been developed. These models, known as "giant models," have demonstrated state-of-the-art performance in various tasks but require substantial computational resources for training and inference. Efficiently managing and training models with a large number of parameters is an active area of research in the AI community.
        unit: ''
        display:
          numDecimalPlaces: 0
          zeroDay: '1949-01-01'
          yearIsDay: true
      training_compute__flop:
        title: Training compute (FLOP)
        unit: 'FLOP'
        display:
          title: Training compute
          numDecimalPlaces: 0
          zeroDay: '1949-01-01'
          yearIsDay: true
      training_dataset_size__datapoints:
        title: Training dataset size
        unit: 'datapoints'
        display:
          numDecimalPlaces: 0
          zeroDay: '1949-01-01'
          yearIsDay: true
      training_time__hours:
        title: Training time
        unit: 'hours'
        display:
          numDecimalPlaces: 0
          zeroDay: '1949-01-01'
          yearIsDay: true
      equivalent_training_time__hours:
        title: Equivalent training time
        unit: 'hours'
        display:
          numDecimalPlaces: 0
          zeroDay: '1949-01-01'
          yearIsDay: true
      training_computation_petaflop:
        title: Training compute (petaFLOP)
        unit: 'petaFLOP'
        description: >-
          Training compute, often measured in petaFLOPs (peta floating-point operations per second), refers to the computational power or performance required to train machine learning models. It represents the speed at which a system can perform mathematical operations, particularly floating-point operations, which are commonly used in machine learning computations.


          Machine learning models, especially deep learning models, involve complex mathematical calculations that require significant computational resources. Training these models involves feeding large amounts of data through various layers and nodes, adjusting weights and parameters, and optimizing the model's performance through iterations of forward and backward propagation.


          The petaFLOP metric is used to quantify the number of floating-point operations that a system can perform in one second. One petaFLOP is equal to one quadrillion (10^15) floating-point operations per second. It provides an estimation of the computational power available to process large datasets and perform the intensive calculations required during the training phase of machine learning models.


          The training compute requirements can vary depending on factors such as the size of the dataset, complexity of the model architecture, and the level of parallelism utilized during the training process. Large-scale deep learning models often require substantial training compute, with the compute requirements measured in petaFLOPs.
        display:
            title: Training compute
            numDecimalPlaces: 0
            zeroDay: '1949-01-01'
            yearIsDay: true


