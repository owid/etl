# NOTE: To learn more about the fields, hover over their names.
definitions:
  common:
    processing_level: major
    presentation:
      topic_tags:
        - Artificial Intelligence
    display:
      zeroDay: '2000-01-01'
      yearIsDay: true
      numDecimalPlaces: 0
    description_processing: |-
      - Reporting a time series of AI investments in nominal prices (i.e., without adjusting for inflation) means it makes little sense to compare observations across time; it is therefore not very useful. To make comparisons across time possible, one has to take into account that prices change (e.g., there is inflation).
      - It is not obvious how to adjust this time series for inflation, and we debated it at some length within our team.
      - It would be straightforward to adjust the time series for price changes if we knew the prices of the specific goods and services that these investments purchased. This would make it possible to calculate a volume measure of AI investments, and it would tell us how much these investments bought. But such a metric is not available. While a comprehensive price index is not available, we know that the cost for some crucial AI technology has fallen rapidly in price.
      - In the absence of a comprehensive price index that captures the price of AI-specific goods and services, one has to rely on one of the available metrics for the price of a bundle of goods and services. In the end we decided to use the US Consumer Price Index (CPI).
      - The US CPI does not provide us with a volume measure of AI goods and services, but it does capture the opportunity costs of these investments. The inflation adjustment of this time series of AI investments therefore lets us understand the size of these investments relative to whatever else these sums of money could have purchased.

dataset:
  update_period_days: 365

tables:
  epoch_gpus:
    variables:

      manufacturer:
        title: Manufacturer
        unit: ''
        short_unit: ''
        description_short: The company that produced the hardware.

      comp_performance_per_dollar:
        title: Computational performance per dollar
        unit: FLOP/s/$
        description_short: Hardware computational performance shown in [floating-point operations](#dod:flop) per second (FLOP/s) per US dollar, adjusted for inflation.
        description_key:
          - Measures how much computing power you get per dollar when buying a GPU.
          - GPUs (graphics processing units) are specialized computer chips that can perform many calculations simultaneously, making them ideal for training AI systems.
          - Only includes GPUs actually used to train notable AI models or specifically designed for machine learning tasks. Excludes other processor types like TPUs and CPUs.
          - Performance measured using AI-specific benchmark tests; prices are the launch prices when GPUs first became available.
          - Values shown as FLOP/s per dollarâ€”meaning how many floating-point operations per second the GPU can perform for each dollar of its price. All prices adjusted for inflation to 2024 US dollars using the Consumer Price Index.
          - Performance measured using FP32 (32-bit floating-point), a standard precision level that represents numbers to about 7 decimal places. This ensures fair comparisons across different hardware, though newer GPUs often support faster but less precise formats.
          - As this metric has improved over time, the cost of training AI systems has decreased dramatically.
        presentation:
          grapher_config:
            note: FLOP/s values refer to 32-bit (full) precision. Data is expressed in constant 2024 US$. Inflation adjustment is based on the US Consumer Price Index (CPI).
