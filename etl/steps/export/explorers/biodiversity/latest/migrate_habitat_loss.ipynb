{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myml.nbinit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-10 09:42:04\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mYou're on master branch, using local env instead of STAGING=master\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from etl.files import yaml_dump\n",
    "\n",
    "def move_field_to_top(data, field):\n",
    "    \"\"\"\n",
    "    Returns a new dictionary with the specified field moved to the top.\n",
    "    If the field doesn't exist, returns the original dictionary.\n",
    "    \"\"\"\n",
    "    if field not in data:\n",
    "        return data\n",
    "\n",
    "    # Create a new dictionary starting with the specified field\n",
    "    new_data = {field: data[field]}\n",
    "\n",
    "    # Add the remaining items in their original order\n",
    "    for key, value in data.items():\n",
    "        if key != field:\n",
    "            new_data[key] = value\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def dump_yaml_with_anchors(data):\n",
    "    \"\"\"\n",
    "    Dump a dictionary to a YAML string, converting definition keys to anchors\n",
    "    and replacing quoted alias strings with YAML aliases.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The dictionary to dump.\n",
    "\n",
    "    Returns:\n",
    "        str: The YAML string with anchors and aliases.\n",
    "    \"\"\"\n",
    "    # Dump the dict to a YAML string. Using default_flow_style=False to get block style.\n",
    "    dumped = yaml_dump(data)\n",
    "\n",
    "    # For any key in the definitions block starting with \"def_\",\n",
    "    # insert an anchor. This regex finds lines with an indented key that starts with def_.\n",
    "    dumped = re.sub(\n",
    "        r\"^(\\s+)(def_[^:]+):(.*)$\",\n",
    "        lambda m: f\"{m.group(1)}{m.group(2)}: &{m.group(2)}{m.group(3)}\",\n",
    "        dumped,\n",
    "        flags=re.MULTILINE\n",
    "    )\n",
    "\n",
    "    # Replace quoted alias strings like '*def_2329260084214905053'\n",
    "    # with an unquoted alias *def_2329260084214905053.\n",
    "    dumped = re.sub(\n",
    "        r\"\"\"(['\"])(\\*def_[^'\"]+)\\1\"\"\",\n",
    "        lambda m: m.group(2),\n",
    "        dumped\n",
    "    )\n",
    "\n",
    "    return dumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TableURLNotInCataloException",
     "evalue": "https://raw.githubusercontent.com/owid/owid-datasets/master/datasets/Biodiversity%20habitat%20loss%20(Williams%20et%20al.%202021)/Biodiversity%20habitat%20loss%20(Williams%20et%20al.%202021).csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTableURLNotInCataloException\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01metl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfiles\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m yaml_dump\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01metl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EXPLORERS_DIR, STEP_DIR\n\u001b[0;32m----> 7\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mmigrate_csv_explorer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhabitat-loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/etl/etl/collections/explorer_migration.py:420\u001b[0m, in \u001b[0;36mmigrate_csv_explorer\u001b[0;34m(name, owid_env)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m migration\u001b[38;5;241m.\u001b[39mtypes \u001b[38;5;241m!=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Not a CSV explorer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 420\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mmigration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m~/projects/etl/etl/collections/explorer_migration.py:322\u001b[0m, in \u001b[0;36mExplorerMigration.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m--> 322\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindicator\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotSupportedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot supported. Soon will be.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/etl/etl/collections/explorer_migration.py:129\u001b[0m, in \u001b[0;36mExplorerMigration.run_csv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(block[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Relevant information about table\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m table_uri \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_table_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m table_slug \u001b[38;5;241m=\u001b[39m block[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Save table slug to URI mapping\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/etl/etl/collections/explorer_migration.py:345\u001b[0m, in \u001b[0;36m_extract_table_uri\u001b[0;34m(catalog_url)\u001b[0m\n\u001b[1;32m    343\u001b[0m     extracted_fragment \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TableURLNotInCataloException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Don't keep full path like `explorers/who/latest/flu/flu`, but only keep the table name\u001b[39;00m\n\u001b[1;32m    348\u001b[0m extracted_fragment \u001b[38;5;241m=\u001b[39m extracted_fragment\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTableURLNotInCataloException\u001b[0m: https://raw.githubusercontent.com/owid/owid-datasets/master/datasets/Biodiversity%20habitat%20loss%20(Williams%20et%20al.%202021)/Biodiversity%20habitat%20loss%20(Williams%20et%20al.%202021).csv"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from collections import defaultdict\n",
    "from etl.collections.explorer_migration import migrate_csv_explorer\n",
    "from etl.files import yaml_dump\n",
    "from etl.paths import EXPLORERS_DIR, STEP_DIR\n",
    "\n",
    "config = migrate_csv_explorer(\"habitat-loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from collections import defaultdict\n",
    "from etl.collections.explorer_migration import migrate_csv_explorer\n",
    "from etl.files import yaml_dump\n",
    "from etl.paths import EXPLORERS_DIR, STEP_DIR\n",
    "\n",
    "config = migrate_csv_explorer(\"influenza\")\n",
    "# print(yaml.dump(config))\n",
    "# config = yaml.safe_load(yaml_dump(config))\n",
    "\n",
    "definitions = defaultdict(dict)\n",
    "\n",
    "for view in config[\"views\"]:\n",
    "    # Move to common_views\n",
    "    del view['config']['timelineMinTime']\n",
    "\n",
    "    # Create shared definitions\n",
    "    for indicator in view[\"indicators\"]['y']:\n",
    "        # Move some fields into definitions\n",
    "        display = indicator['display']\n",
    "        for key in ('additionalInfo', 'sourceLink', 'dataPublishedBy', 'sourceName'):\n",
    "            info = display[key]\n",
    "            info = info.replace('\\\\n', '\\n')\n",
    "\n",
    "            h = \"def_\" + str(abs(hash(display[key])))\n",
    "\n",
    "            definitions[key][h] = info\n",
    "            display[key] = '*' + h\n",
    "\n",
    "definitions['common_views'] = [\n",
    "    {\n",
    "        \"config\": {\n",
    "            \"timelineMinTime\": \"-4043\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "config[\"definitions\"] = definitions\n",
    "\n",
    "config = move_field_to_top(config, \"definitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract display for indicators\n",
    "\n",
    "tables = defaultdict(dict)\n",
    "\n",
    "for view in config['views']:\n",
    "    for ind in view['indicators']['y']:\n",
    "        table_name, col = ind['catalogPath'].split('#')\n",
    "        if 'variables' not in tables[table_name]:\n",
    "            tables[table_name]['variables'] = {}\n",
    "        variable_entry = {\n",
    "            \"title\": col,\n",
    "            'unit': ind['display'].pop('unit')\n",
    "        }\n",
    "        variable_entry[\"display\"] = {\n",
    "            \"name\": ind['display'].pop('name')\n",
    "        }\n",
    "        if 'shortUnit' in ind['display']:\n",
    "            variable_entry['short_unit'] = ind['display'].pop('shortUnit')\n",
    "        tables[table_name]['variables'][col] = variable_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump explorer config\n",
    "path_new = STEP_DIR / \"export/explorers/who/latest/influenza.config.yml\"\n",
    "with open(path_new, \"w\") as f:\n",
    "    f.write(dump_yaml_with_anchors(config))\n",
    "\n",
    "# dump metadata for the grapher step\n",
    "# path_new = STEP_DIR / \"data/grapher/who/latest/flu.meta.yml\"\n",
    "# with open(path_new, \"w\") as f:\n",
    "#     f.write(yaml_dump({\"tables\": tables}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
